{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ÿäÿßÿ±ÿ® ÿ£ŸÅŸàÿ≤ üò´üò´‚ô•Ô∏è‚ô•Ô∏è #ÿ≠ÿßÿ¥Ÿä_ÿ®ÿßÿ¥ÿß_50ŸÅÿ±ÿπ ÿπ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#ÿ≠ÿßÿ¥Ÿä_ÿ®ÿßÿ¥ÿß_50ŸÅÿ±ÿπ ÿßŸÑŸÑŸáŸÖ ÿßÿ∫ÿ´ ÿßŸÑÿ®ŸÑÿßÿØ ŸàÿßŸÑÿπÿ®ÿßÿØ</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       tweet  label\n",
       "0        Ÿäÿßÿ±ÿ® ÿ£ŸÅŸàÿ≤ üò´üò´‚ô•Ô∏è‚ô•Ô∏è #ÿ≠ÿßÿ¥Ÿä_ÿ®ÿßÿ¥ÿß_50ŸÅÿ±ÿπ ÿπ      0\n",
       "1  #ÿ≠ÿßÿ¥Ÿä_ÿ®ÿßÿ¥ÿß_50ŸÅÿ±ÿπ ÿßŸÑŸÑŸáŸÖ ÿßÿ∫ÿ´ ÿßŸÑÿ®ŸÑÿßÿØ ŸàÿßŸÑÿπÿ®ÿßÿØ      0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import random\n",
    "import gensim\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "%matplotlib inline\n",
    "df_text = pd.read_csv (\"/home/niddal/Desktop/PhD_projects/Twitter_analysis/Datasets/MHC_Datasets/Final_ones/Full_Dataset_Text.csv\")\n",
    "df_text.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_df= df_text[df_text['label'] == 0]\n",
    "spam_df= df_text[df_text['label'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text_New = df_text[pd.notnull(df_text['tweet'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34239"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text_New['tweet'].apply(lambda x: len(x.split(' '))).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlwAAAD1CAYAAACFkCu/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAASXElEQVR4nO3df6xfdX3H8edrrRI2JcNxIaU/1uqKW0u2Gm46EqNhYRudLhaXuLVZhDmSKoFEEv8Q3B+aJU3YJpqQzZo6CZA4sBsizRQnEicxQ/GCHaVg5fJDuLRpr7BMFk23lvf+uKfzu8u3ve2993Pv/V6ej+Tke77v8/mc8/n+c/PK+XzOuakqJEmS1M4vzPcAJEmSFjsDlyRJUmMGLkmSpMYMXJIkSY0ZuCRJkhozcEmSJDW2dL4HMJVzzjmnVq9ePd/DkCRJmtLDDz/846oamlxf8IFr9erVjIyMzPcwJEmSppTkR/3qTilKkiQ1ZuCSJElqzMAlSZLU2JSBK8nKJN9M8kSSfUk+3NXflOS+JE92n2f39LkhyWiS/Uku66lflGRvd+zmJGnzsyRJkhaOU7nDdRT4SFX9BnAxcE2SdcD1wP1VtRa4v/tOd2wLsB7YBHwmyZLuXDuAbcDabts0i79FkiRpQZoycFXVwap6pNt/GXgCWA5sBm7rmt0GXN7tbwburKojVfUMMApsTLIMOKuqHqyqAm7v6SNJkrRondYariSrgbcB3wXOq6qDMBHKgHO7ZsuB53u6jXW15d3+5LokSdKidsqBK8kbgLuA66rqJydr2qdWJ6n3u9a2JCNJRsbHx091iJIkSQvSKb34NMnrmAhbX6iqL3XlQ0mWVdXBbrrwcFcfA1b2dF8BHOjqK/rUX6WqdgI7AYaHh/uGstey1dd/Zb6HoAHy7I3vnu8hSNJr3qk8pRjg88ATVfWpnkO7gSu7/SuBe3rqW5KckWQNE4vjH+qmHV9OcnF3zit6+kiSJC1ap3KH6+3A+4G9SfZ0tY8BNwK7klwFPAe8D6Cq9iXZBTzOxBOO11TVsa7f1cCtwJnAvd0mSZK0qE0ZuKrq2/RffwVw6Qn6bAe296mPABeezgAlSZIGnW+alyRJaszAJUmS1JiBS5IkqTEDlyRJUmMGLkmSpMYMXJIkSY0ZuCRJkhozcEmSJDVm4JIkSWrMwCVJktSYgUuSJKkxA5ckSVJjBi5JkqTGDFySJEmNGbgkSZIaM3BJkiQ1ZuCSJElqbMrAleSWJIeTPNZT+2KSPd32bJI9XX11kp/1HPtsT5+LkuxNMprk5iRp85MkSZIWlqWn0OZW4G+B248XqupPju8nuQn4z572T1XVhj7n2QFsA74DfBXYBNx7+kOWJEkaLFPe4aqqB4CX+h3r7lL9MXDHyc6RZBlwVlU9WFXFRHi7/PSHK0mSNHhmuobrHcChqnqyp7YmyfeTfCvJO7racmCsp81YV5MkSVr0TmVK8WS28v/vbh0EVlXVi0kuAr6cZD3Qb71WneikSbYxMf3IqlWrZjhESZKk+TXtO1xJlgJ/BHzxeK2qjlTVi93+w8BTwAVM3NFa0dN9BXDgROeuqp1VNVxVw0NDQ9MdoiRJ0oIwkynF3wV+UFX/N1WYZCjJkm7/zcBa4OmqOgi8nOTibt3XFcA9M7i2JEnSwDiV10LcATwIvDXJWJKrukNbePVi+XcCjyb5d+CfgA9V1fEF91cDfw+MMnHnyycUJUnSa8KUa7iqausJ6n/Wp3YXcNcJ2o8AF57m+CRJkgaeb5qXJElqzMAlSZLUmIFLkiSpMQOXJElSYwYuSZKkxgxckiRJjRm4JEmSGjNwSZIkNWbgkiRJaszAJUmS1JiBS5IkqTEDlyRJUmMGLkmSpMYMXJIkSY0ZuCRJkhozcEmSJDVm4JIkSWpsysCV5JYkh5M81lP7RJIXkuzptnf1HLshyWiS/Uku66lflGRvd+zmJJn9nyNJkrTwnModrluBTX3qn66qDd32VYAk64AtwPquz2eSLOna7wC2AWu7rd85JUmSFp0pA1dVPQC8dIrn2wzcWVVHquoZYBTYmGQZcFZVPVhVBdwOXD7dQUuSJA2SmazhujbJo92U49ldbTnwfE+bsa62vNufXJckSVr0phu4dgBvATYAB4Gbunq/dVl1knpfSbYlGUkyMj4+Ps0hSpIkLQzTClxVdaiqjlXVK8DngI3doTFgZU/TFcCBrr6iT/1E599ZVcNVNTw0NDSdIUqSJC0Y0wpc3Zqs494LHH+CcTewJckZSdYwsTj+oao6CLyc5OLu6cQrgHtmMG5JkqSBsXSqBknuAC4BzkkyBnwcuCTJBiamBZ8FPghQVfuS7AIeB44C11TVse5UVzPxxOOZwL3dJkmStOhNGbiqamuf8udP0n47sL1PfQS48LRGJ0mStAj4pnlJkqTGDFySJEmNGbgkSZIaM3BJkiQ1ZuCSJElqzMAlSZLUmIFLkiSpMQOXJElSYwYuSZKkxgxckiRJjRm4JEmSGjNwSZIkNWbgkiRJaszAJUmS1JiBS5IkqTEDlyRJUmMGLkmSpMamDFxJbklyOMljPbW/SfKDJI8muTvJL3f11Ul+lmRPt322p89FSfYmGU1yc5K0+UmSJEkLy6nc4boV2DSpdh9wYVX9JvBD4IaeY09V1YZu+1BPfQewDVjbbZPPKUmStChNGbiq6gHgpUm1r1fV0e7rd4AVJztHkmXAWVX1YFUVcDtw+fSGLEmSNFhmYw3XnwP39nxfk+T7Sb6V5B1dbTkw1tNmrKtJkiQtektn0jnJXwBHgS90pYPAqqp6MclFwJeTrAf6rdeqk5x3GxPTj6xatWomQ5QkSZp3077DleRK4A+BP+2mCamqI1X1Yrf/MPAUcAETd7R6px1XAAdOdO6q2llVw1U1PDQ0NN0hSpIkLQjTClxJNgEfBd5TVT/tqQ8lWdLtv5mJxfFPV9VB4OUkF3dPJ14B3DPj0UuSJA2AKacUk9wBXAKck2QM+DgTTyWeAdzXvd3hO90Tie8E/jLJUeAY8KGqOr7g/momnng8k4k1X73rviRJkhatKQNXVW3tU/78CdreBdx1gmMjwIWnNTpJkqRFwDfNS5IkNWbgkiRJaszAJUmS1JiBS5IkqTEDlyRJUmMGLkmSpMYMXJIkSY0ZuCRJkhozcEmSJDVm4JIkSWrMwCVJktSYgUuSJKkxA5ckSVJjBi5JkqTGDFySJEmNGbgkSZIaM3BJkiQ1ZuCSJElqbMrAleSWJIeTPNZTe1OS+5I82X2e3XPshiSjSfYnuaynflGSvd2xm5Nk9n+OJEnSwnMqd7huBTZNql0P3F9Va4H7u+8kWQdsAdZ3fT6TZEnXZwewDVjbbZPPKUmStChNGbiq6gHgpUnlzcBt3f5twOU99Tur6khVPQOMAhuTLAPOqqoHq6qA23v6SJIkLWrTXcN1XlUdBOg+z+3qy4Hne9qNdbXl3f7kel9JtiUZSTIyPj4+zSFKkiQtDLO9aL7fuqw6Sb2vqtpZVcNVNTw0NDRrg5MkSZoP0w1ch7ppQrrPw119DFjZ024FcKCrr+hTlyRJWvSmG7h2A1d2+1cC9/TUtyQ5I8kaJhbHP9RNO76c5OLu6cQrevpIkiQtakunapDkDuAS4JwkY8DHgRuBXUmuAp4D3gdQVfuS7AIeB44C11TVse5UVzPxxOOZwL3dJkmStOhNGbiqausJDl16gvbbge196iPAhac1OkmSpEXAN81LkiQ1ZuCSJElqzMAlSZLUmIFLkiSpMQOXJElSYwYuSZKkxgxckiRJjRm4JEmSGjNwSZIkNWbgkiRJaszAJUmS1JiBS5IkqTEDlyRJUmMGLkmSpMYMXJIkSY0ZuCRJkhozcEmSJDU27cCV5K1J9vRsP0lyXZJPJHmhp/6unj43JBlNsj/JZbPzEyRJkha2pdPtWFX7gQ0ASZYALwB3Ax8APl1Vn+xtn2QdsAVYD5wPfCPJBVV1bLpjkCRJGgSzNaV4KfBUVf3oJG02A3dW1ZGqegYYBTbO0vUlSZIWrNkKXFuAO3q+X5vk0SS3JDm7qy0Hnu9pM9bVXiXJtiQjSUbGx8dnaYiSJEnzY8aBK8nrgfcA/9iVdgBvYWK68SBw0/GmfbpXv3NW1c6qGq6q4aGhoZkOUZIkaV7Nxh2uPwAeqapDAFV1qKqOVdUrwOf4+bThGLCyp98K4MAsXF+SJGlBm43AtZWe6cQky3qOvRd4rNvfDWxJckaSNcBa4KFZuL4kSdKCNu2nFAGS/CLwe8AHe8p/nWQDE9OFzx4/VlX7kuwCHgeOAtf4hKIkSXotmFHgqqqfAr8yqfb+k7TfDmyfyTUlSZIGjW+alyRJaszAJUmS1JiBS5IkqTEDlyRJUmMGLkmSpMYMXJIkSY0ZuCRJkhozcEmSJDVm4JIkSWrMwCVJktSYgUuSJKkxA5ckSVJjBi5JkqTGDFySJEmNGbgkSZIaM3BJkiQ1ZuCSJElqbEaBK8mzSfYm2ZNkpKu9Kcl9SZ7sPs/uaX9DktEk+5NcNtPBS5IkDYKls3CO36mqH/d8vx64v6puTHJ99/2jSdYBW4D1wPnAN5JcUFXHZmEMkqQZWn39V+Z7CBogz9747vkewkBpMaW4Gbit278NuLynfmdVHamqZ4BRYGOD60uSJC0oMw1cBXw9ycNJtnW186rqIED3eW5XXw4839N3rKu9SpJtSUaSjIyPj89wiJIkSfNrplOKb6+qA0nOBe5L8oOTtE2fWvVrWFU7gZ0Aw8PDfdtIkiQNihnd4aqqA93nYeBuJqYIDyVZBtB9Hu6ajwEre7qvAA7M5PqSJEmDYNqBK8kvJXnj8X3g94HHgN3AlV2zK4F7uv3dwJYkZyRZA6wFHpru9SVJkgbFTKYUzwPuTnL8PP9QVV9L8j1gV5KrgOeA9wFU1b4ku4DHgaPANT6hKEmSXgumHbiq6mngt/rUXwQuPUGf7cD26V5TkiRpEPmmeUmSpMYMXJIkSY0ZuCRJkhozcEmSJDVm4JIkSWrMwCVJktSYgUuSJKkxA5ckSVJjBi5JkqTGDFySJEmNGbgkSZIaM3BJkiQ1ZuCSJElqzMAlSZLUmIFLkiSpMQOXJElSYwYuSZKkxqYduJKsTPLNJE8k2Zfkw139E0leSLKn297V0+eGJKNJ9ie5bDZ+gCRJ0kK3dAZ9jwIfqapHkrwReDjJfd2xT1fVJ3sbJ1kHbAHWA+cD30hyQVUdm8EYJEmSFrxp3+GqqoNV9Ui3/zLwBLD8JF02A3dW1ZGqegYYBTZO9/qSJEmDYlbWcCVZDbwN+G5XujbJo0luSXJ2V1sOPN/TbYwTBLQk25KMJBkZHx+fjSFKkiTNmxkHriRvAO4CrquqnwA7gLcAG4CDwE3Hm/bpXv3OWVU7q2q4qoaHhoZmOkRJkqR5NaPAleR1TIStL1TVlwCq6lBVHauqV4DP8fNpwzFgZU/3FcCBmVxfkiRpEMzkKcUAnweeqKpP9dSX9TR7L/BYt78b2JLkjCRrgLXAQ9O9viRJ0qCYyVOKbwfeD+xNsqerfQzYmmQDE9OFzwIfBKiqfUl2AY8z8YTjNT6hKEmSXgumHbiq6tv0X5f11ZP02Q5sn+41JUmSBpFvmpckSWrMwCVJktSYgUuSJKkxA5ckSVJjBi5JkqTGDFySJEmNGbgkSZIaM3BJkiQ1ZuCSJElqzMAlSZLUmIFLkiSpMQOXJElSYwYuSZKkxgxckiRJjRm4JEmSGjNwSZIkNWbgkiRJamzOA1eSTUn2JxlNcv1cX1+SJGmuzWngSrIE+DvgD4B1wNYk6+ZyDJIkSXNtru9wbQRGq+rpqvpv4E5g8xyPQZIkaU4tnePrLQee7/k+Bvz25EZJtgHbuq//lWT/HIxNg+8c4MfzPYiFJn813yOQBp5/W/rwb8sJ/Wq/4lwHrvSp1asKVTuBne2Ho8UkyUhVDc/3OCQtLv5t0WyY6ynFMWBlz/cVwIE5HoMkSdKcmuvA9T1gbZI1SV4PbAF2z/EYJEmS5tScTilW1dEk1wL/AiwBbqmqfXM5Bi1qTkNLasG/LZqxVL1qCZUkSZJmkW+alyRJaszAJUmS1JiBS5IkqbG5fg+XNGuS/DoT/6lgORPvczsA7K6qJ+Z1YJIkTeIdLg2kJB9l4l9DBXiIiVeOBLjDf4ouqYUkH5jvMWhw+ZSiBlKSHwLrq+p/JtVfD+yrqrXzMzJJi1WS56pq1XyPQ4PJKUUNqleA84EfTaov645J0mlL8uiJDgHnzeVYtLgYuDSorgPuT/IkP/+H6KuAXwOunbdRSRp05wGXAf8xqR7g3+Z+OFosDFwaSFX1tSQXABuZWDQfJv5X5/eq6ti8Dk7SIPtn4A1VtWfygST/OvfD0WLhGi5JkqTGfEpRkiSpMQOXJElSYwYuSZKkxgxckiRJjRm4JEmSGvtfB22FXfkmTBsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "my_tags = ['non_spam','spam']\n",
    "plt.figure(figsize=(10,4))\n",
    "df_text_New.label.value_counts().plot(kind='bar');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_plot(index):\n",
    "    example = df_text_New[df_text_New.index == index][['label', 'tweet']].values[0]\n",
    "    if len(example) > 0:\n",
    "        print(example[0])\n",
    "        print('Tweet:', example[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Tweet: Ÿäÿßÿ±ÿ® ÿ£ŸÅŸàÿ≤ üò´üò´‚ô•Ô∏è‚ô•Ô∏è #ÿ≠ÿßÿ¥Ÿä_ÿ®ÿßÿ¥ÿß_50ŸÅÿ±ÿπ ÿπ\n"
     ]
    }
   ],
   "source": [
    "print_plot(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_pattern(input_txt, pattern):\n",
    "    r = re.findall(pattern, input_txt)\n",
    "    for i in r:\n",
    "        input_txt = re.sub(i, '', input_txt)        \n",
    "    return input_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweets(lst):\n",
    "    # remove twitter Return handles (RT @xxx:)\n",
    "    lst = np.vectorize(remove_pattern)(lst, \"RT @[\\w]*:\")\n",
    "    # remove twitter handles (@xxx)\n",
    "    lst = np.vectorize(remove_pattern)(lst, \"@[\\w]*\")\n",
    "    # remove URL links (httpxxx)\n",
    "    lst = np.vectorize(remove_pattern)(lst, \"https?://[A-Za-z0-9./]*\")\n",
    "    # remove special characters, numbers, punctuations (except for #)\n",
    "    lst = np.core.defchararray.replace(lst, \"[^a-zA-Z#]\", \" \")\n",
    "\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stop_words import get_stop_words\n",
    "stop_words = get_stop_words('arabic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-0c84286979ac>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_text_New['tweet']= clean_tweets(df_text_New['tweet'])\n"
     ]
    }
   ],
   "source": [
    "df_text_New['tweet']= clean_tweets(df_text_New['tweet'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33017"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text_New['tweet'].apply(lambda x: len(x.split(' '))).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#ÿ≠ÿßÿ¥Ÿä_ÿ®ÿßÿ¥ÿß_50ŸÅÿ±ÿπ Ÿäÿ£ÿ™Ÿä ÿ®ŸêŸáÿßŸé ÿßŸÑŸÑŸá ÿ•ŸÜ ÿßŸÑŸÑŸá ŸÑÿ∑ŸäŸÅŸå ÿÆÿ®Ÿäÿ± '"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_text_New.tweet[55]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doc2vec and Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/niddal/anaconda3/envs/py2/lib/python3.8/site-packages/tqdm/std.py:668: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"progress-bar\")\n",
    "from gensim.models import doc2vec\n",
    "from sklearn import utils\n",
    "import gensim\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_sentences(corpus, label_type):\n",
    "    \"\"\"\n",
    "    Gensim's Doc2Vec implementation requires each document/paragraph to have a label associated with it.\n",
    "    We do this by using the TaggedDocument method. The format will be \"TRAIN_i\" or \"TEST_i\" where \"i\" is\n",
    "    a dummy index of the post.\n",
    "    \"\"\"\n",
    "    labeled = []\n",
    "    for i, v in enumerate(corpus):\n",
    "        label = label_type + '_' + str(i)\n",
    "        labeled.append(doc2vec.TaggedDocument(v.split(), [label]))\n",
    "    return labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_text_New.tweet, df_text_New.label, random_state=0, test_size=0.3)\n",
    "X_train = label_sentences(X_train, 'Train')\n",
    "X_test = label_sentences(X_test, 'Test')\n",
    "all_data = X_train + X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TaggedDocument(words=['RT', '@4YkskI0WIIIWUHX:', '#ÿ™ÿ±ŸÉŸä_ÿßŸÑ_ÿ¥ŸäÿÆ_ÿßÿØÿπŸÖ_ÿ™Ÿàÿ®_ÿ±ÿßŸäÿØ', 'ÿ®ÿ±ÿßÿ™ÿ®', 'Ÿäÿ®ÿØÿ£', 'ŸÖŸÜ', 'Ÿ°Ÿ†Ÿ†Ÿ†', 'ÿßŸÑŸâŸ¢Ÿ†Ÿ†Ÿ†', 'ÿ±ŸäÿßŸÑ', 'ÿ®ÿØŸàŸÜ', 'ÿØŸàÿßŸÖ', 'ÿßŸÑÿπÿØÿØ', 'ÿßŸÑŸÖÿ∑ŸÑŸàÿ®', '20', 'ŸÅŸÇÿ∑', 'ÿßŸÑÿÆÿßÿµ', 'ŸÖŸÅÿ™Ÿàÿ≠', 'ŸÑŸÑÿ™ÿ≥ÿ¨ŸäŸÑ', 'ÿ±‚Ä¶'], tags=['Train_2'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2508/2508 [00:00<00:00, 3022791.50it/s]\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Doc2Vec\n",
    "\n",
    "model_dbow = Doc2Vec(dm=0, vector_size=300, negative=5, min_count=1, alpha=0.065, min_alpha=0.065)\n",
    "model_dbow.build_vocab([x for x in tqdm(all_data)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2508/2508 [00:00<00:00, 629409.11it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2508/2508 [00:00<00:00, 3062391.39it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2508/2508 [00:00<00:00, 3187671.04it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2508/2508 [00:00<00:00, 3888840.83it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2508/2508 [00:00<00:00, 2831578.58it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2508/2508 [00:00<00:00, 3657619.76it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2508/2508 [00:00<00:00, 3586537.48it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2508/2508 [00:00<00:00, 3606209.95it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2508/2508 [00:00<00:00, 3569499.30it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2508/2508 [00:00<00:00, 1413696.34it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2508/2508 [00:00<00:00, 3978560.68it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2508/2508 [00:00<00:00, 3453484.71it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2508/2508 [00:00<00:00, 2582060.49it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2508/2508 [00:00<00:00, 2399478.66it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2508/2508 [00:00<00:00, 3744860.96it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2508/2508 [00:00<00:00, 3467143.85it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2508/2508 [00:00<00:00, 3858882.77it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2508/2508 [00:00<00:00, 1467947.87it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2508/2508 [00:00<00:00, 3582872.76it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2508/2508 [00:00<00:00, 3534715.87it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2508/2508 [00:00<00:00, 3341586.54it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2508/2508 [00:00<00:00, 3987609.72it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2508/2508 [00:00<00:00, 3302767.48it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2508/2508 [00:00<00:00, 3644946.10it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2508/2508 [00:00<00:00, 3814109.66it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2508/2508 [00:00<00:00, 3285232.49it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2508/2508 [00:00<00:00, 3932453.99it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2508/2508 [00:00<00:00, 3587760.72it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2508/2508 [00:00<00:00, 3056163.40it/s]\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2508/2508 [00:00<00:00, 2156923.20it/s]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(30):\n",
    "    model_dbow.train(utils.shuffle([x for x in tqdm(all_data)]), total_examples=len(all_data), epochs=1)\n",
    "    model_dbow.alpha -= 0.002\n",
    "    model_dbow.min_alpha = model_dbow.alpha\n",
    "    \n",
    "model_dbow.save('./doc2vec.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Doc2Vec.load('./doc2vec.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectors(model, corpus_size, vectors_size, vectors_type):\n",
    "    \"\"\"\n",
    "    Get vectors from trained doc2vec model\n",
    "    :param doc2vec_model: Trained Doc2Vec model\n",
    "    :param corpus_size: Size of the data\n",
    "    :param vectors_size: Size of the embedding vectors\n",
    "    :param vectors_type: Training or Testing vectors\n",
    "    :return: list of vectors\n",
    "    \"\"\"\n",
    "    vectors = np.zeros((corpus_size, vectors_size))\n",
    "    for i in range(0, corpus_size):\n",
    "        prefix = vectors_type + '_' + str(i)\n",
    "        vectors[i] = model.docvecs[prefix]\n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors_dbow = get_vectors(model_dbow, len(X_train), 300, 'Train')\n",
    "test_vectors_dbow = get_vectors(model_dbow, len(X_test), 300, 'Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#logreg = LogisticRegression(n_jobs=1, C=1e5)\n",
    "logreg = RandomForestClassifier()\n",
    "logreg.fit(train_vectors_dbow, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = logreg.fit(train_vectors_dbow, y_train)\n",
    "y_pred = logreg.predict(test_vectors_dbow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.9960159362549801\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    non_spam       1.00      1.00      1.00       602\n",
      "        spam       0.98      1.00      0.99       151\n",
      "\n",
      "    accuracy                           1.00       753\n",
      "   macro avg       0.99      1.00      0.99       753\n",
      "weighted avg       1.00      1.00      1.00       753\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_pred,y_test, target_names=my_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = 'ŸÉŸäŸÅ'\n",
    "#string = 'ÿ≠ÿßÿ¥Ÿä_ÿ®ÿßÿ¥ÿß_50ŸÅÿ±ÿπ Ÿäÿ£ÿ™Ÿä ÿ®ŸêŸáÿßŸé ÿßŸÑŸÑŸá ÿ•ŸÜ ÿßŸÑŸÑŸá ŸÑÿ∑ŸäŸÅŸå ÿÆÿ®Ÿäÿ±'\n",
    "#string = ' Ÿàÿ®ŸÇŸÑŸÉ ŸÉŸäŸÅ ÿ™ÿÆÿ≥ ŸÅŸä ÿßÿ≥ÿ±ÿπ ŸàŸÇÿ™ ÿ®ÿØŸàŸÜ ÿπŸÖŸÑŸäÿßÿ™ ÿ£Ÿà ÿ™ÿπŸÄŸÄÿ®..üò∑üíâ\\nŸÖÿπ ÿßŸÇŸàŸâ ÿ®ÿ±ÿßŸÖÿ¨ ÿßŸÑÿ™ÿÆÿ≥Ÿäÿ≥ ÿßŸÑÿµÿ≠Ÿäÿ©\\n#ŸÖÿ≠ŸÖÿØ_ÿ®ŸÜ_ÿ≥ŸÑŸÖÿßŸÜ_ÿ®ŸäŸÜ_ÿßŸáŸÑ_ÿ≠ÿßŸäŸÑ‚Üó ÿ£ÿ±ÿ≥ŸÑ Ÿàÿ≤ŸÜŸÉ Ÿàÿ∑ŸàŸÑŸÉ ÿπÿ®ÿ± ÿßŸÑÿÆÿßÿµ.. üì¨'\n",
    "\n",
    "lists= string.split(' ')\n",
    "inferred_vector=model_dbow.infer_vector(doc_words=lists,alpha=0.025,steps=500)\n",
    "ddf = pd.DataFrame(columns=['tag', 'd2v_Vec'])\n",
    "ddf.loc[0,'d2v_Vec']=list(inferred_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction : [0]\n"
     ]
    }
   ],
   "source": [
    "predict=logreg.predict(list(ddf['d2v_Vec']))\n",
    "print(\"prediction :\", predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
